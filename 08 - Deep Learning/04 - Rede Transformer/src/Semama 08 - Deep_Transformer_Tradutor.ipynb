{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYGwZGsyn-p1"
      },
      "source": [
        "# Tradução de Inglês para Português utilizando um Modelo Transformer Sequence-to-Sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ipqJygzn-p2"
      },
      "source": [
        "## Introdução\n",
        "Neste exemplo, vamos construir um modelo Transformer de sequência para sequência (sequence-to-sequence ), que será treinado em uma tarefa de tradução automática do inglês para o português.\n",
        "\n",
        "Você aprenderá:\n",
        "\n",
        "- Vetorizar texto usando a camada TextVectorization do Keras.\n",
        "- Implementar uma camada TransformerEncoder, uma camada TransformerDecoder e uma camada PositionalEmbedding.\n",
        "- Preparar os dados para o treinamento de um modelo de *sequence-to-sequence*.\n",
        "- Usar o modelo treinado para gerar traduções de frases nunca vistas anteriormente.\n",
        "\n",
        "O código original foi adaptado do livro Deep Learning with Python <(https://www.manning.com/books/deep-learning-with-python-second-edition)> e dos exemplos do Keras <https://keras.io/examples/nlp/neural_machine_translation_with_transformer/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9ZcYa_Nn-p2"
      },
      "source": [
        "#**Importando as bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bhH2k9wsn-p3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfAMaLJwn-p4"
      },
      "source": [
        "**Analisando os dados**\n",
        "\n",
        "Cada linha contém uma frase em inglês e sua respectiva tradução em português.\n",
        "A frase em inglês é a sequência de origem e a frase em inglês é a sequência de destino.\n",
        "Adicionamos o token \"[start]\" no início e o token \"[end]\" no final da frase em português."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-vJ0tBukn-p4"
      },
      "outputs": [],
      "source": [
        "# Abre o arquivo chamado 'port4.txt' no modo leitura\n",
        "# O arquivo é atribuído à variável f\n",
        "#\n",
        "with open('port4.txt') as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1] # Lê todas as linhas do arquivo e as divide em uma lista, removendo a última linha vazia\n",
        "text_pairs = [] # Inicializa uma lista vazia para armazenar os pares de texto inglês -> português\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkcWtnTIn-p4"
      },
      "source": [
        "#**Formatando os pares de frases:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Itera sobre cada linha da lista 'lines', onde cada linha contém uma frase em inglês\n",
        "# e sua tradução em português, separadas por tabulação (\\t)\n",
        "for line in lines:\n",
        "\n",
        "    # Divide a linha usando '\\t' como delimitador e atribui as partes às variáveis 'eng' e 'por'.\n",
        "    # 'eng' = frase em inglês (sequência de entrada)\n",
        "    # 'por' = frase em português (sequência de saída, antes de adicionar os tokens)\n",
        "    eng, por = line.split(\"\\t\")\n",
        "\n",
        "    # Adiciona os tokens especiais \"[start]\" no início e \"[end]\" no final da frase em português.\n",
        "    # Isso ajuda o modelo seq2seq a reconhecer o início e o fim da sequência de saída durante a tradução.\n",
        "    por = \"[start] \" + por + \" [end]\"\n",
        "\n",
        "    # Adiciona o par processado (frase em inglês, frase em português com tokens) à lista 'text_pairs'\n",
        "    text_pairs.append((eng, por))\n",
        "\n",
        "# Imprime o primeiro item da lista 'text_pairs' (o índice começa em 0), ou seja,\n",
        "# o primeiro par de tradução processado\n",
        "print(text_pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxx_WNJIEvld",
        "outputId": "e4081c37-3905-4dbe-d3ca-6005e299bdcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Go.', '[start] Vai. [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR3Eb1T0n-p5"
      },
      "source": [
        "# **Criando os conjuntos de treinamento, validação e teste.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cFNLb25En-p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da86a18e-92b9-44e3-d4a1-ea7c43eac652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196350 total de pares do conjunto de amostras\n",
            "137446 conjunto de treinamento\n",
            "29452 conjunto de validação\n",
            "29452 conjunto de teste\n"
          ]
        }
      ],
      "source": [
        "# Embaralha a lista de pares de texto (text_pairs)\n",
        "# Isso é importante antes de dividir os dados em conjuntos de treino, validação e teste\n",
        "random.shuffle(text_pairs)\n",
        "\n",
        "# Calcula o número de amostras para o conjunto de validação (15% do total)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "\n",
        "# Calcula o número de amostras para o conjunto de treinamento\n",
        "# O restante será dividido entre validação e teste (70% para treino, 15% para validação, 15% para teste)\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "# Define o conjunto de treinamento: primeiras 'num_train_samples' amostras\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "\n",
        "# Define o conjunto de validação: próximas 'num_val_samples' amostras após o treinamento\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "\n",
        "# Define o conjunto de teste: amostras restantes após o treinamento e validação\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "\n",
        "# Imprime informações sobre o tamanho total de pares\n",
        "print(f\"{len(text_pairs)} total de pares do conjunto de amostras\")\n",
        "\n",
        "# Imprime o número de pares de frases usadas para treinamento\n",
        "print(f\"{len(train_pairs)} conjunto de treinamento\")\n",
        "\n",
        "# Imprime o número de pares de frases usadas para validação\n",
        "print(f\"{len(val_pairs)} conjunto de validação\")\n",
        "\n",
        "# Imprime o número de pares de frases usadas para teste\n",
        "print(f\"{len(test_pairs)} conjunto de teste\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH2NYZ7_n-p5"
      },
      "source": [
        " **Vetorizando os dados de texto**\n",
        "\n",
        "Usaremos duas instâncias da camada TextVectorization para vetorizar os dados de texto (uma para o inglês e uma para o português), ou seja, transformar as strings originais em sequências de inteiros, onde cada inteiro representa o índice de uma palavra no vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EXwehVsKn-p5"
      },
      "outputs": [],
      "source": [
        "# Define o tamanho máximo do vocabulário (número máximo de palavras a serem consideradas)\n",
        "vocab_size = 15000\n",
        "\n",
        "# Define o comprimento máximo das sequências (cada frase será truncada ou preenchida até esse valor)\n",
        "sequence_length = 20\n",
        "\n",
        "# Define o número de amostras por lote durante o treinamento do modelo\n",
        "batch_size = 64\n",
        "\n",
        "# Cria uma camada TextVectorization para o inglês\n",
        "eng_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,          # Máximo de tokens no vocabulário\n",
        "    output_mode=\"int\",              # Saída como números inteiros (índices de palavras)\n",
        "    output_sequence_length=sequence_length,  # Comprimento fixo das sequências\n",
        ")\n",
        "\n",
        "# Cria uma camada TextVectorization para o português\n",
        "por_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,          # Mesmo tamanho de vocabulário\n",
        "    output_mode=\"int\",              # Saída como números inteiros\n",
        "    output_sequence_length=sequence_length + 1,  # Um pouco mais longa (para incluir [start] e [end])\n",
        "    #standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "# Extrai apenas as frases em inglês dos pares de treinamento\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "\n",
        "# Extrai apenas as frases em português dos pares de treinamento\n",
        "train_por_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# Ajusta (adapta) o vetorizador de inglês ao conjunto de dados de treino\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "\n",
        "# Ajusta (adapta) o vetorizador de português ao conjunto de dados de treino\n",
        "por_vectorization.adapt(train_por_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRZOMYbHn-p6"
      },
      "source": [
        "#**Formatando os conjuntos de dados**\n",
        "\n",
        "Em cada passo do treinamento, o modelo tentará prever as palavras N+1 (e as posteriores) da sequência alvo usando:\n",
        "\n",
        "a frase de entrada, e as palavras de destino de 0 até N.\n",
        "Dessa forma, o conjunto de dados de treinamento retornará uma tupla (inputs, targets), onde:\n",
        "\n",
        "* *inputs* é um dicionário com as chaves *encoder_inputs* e *decoder_inputs*.\n",
        "\n",
        "* *encoder_inputs* é a frase fonte vetorizada.\n",
        "\n",
        "* *decoder_inputs* é a frase alvo \"até o momento\", ou seja, as palavras de 0 até N usadas para prever a palavra N+1 (e as posteriores) na frase alvo.\n",
        "\n",
        "* *target* é a frase alvo deslocada em um passo:\n",
        "ela fornece as próximas palavras na frase alvo — aquelas que o modelo tentará prever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Pplm5BbOn-p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfa2219-c645-4da2-ae76-1e0a8ec594c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "def format_dataset(eng, por):\n",
        "    # Vetoriza as frases em inglês usando a camada TextVectorization pré-adaptada\n",
        "    eng = eng_vectorization(eng)\n",
        "\n",
        "    # Vetoriza as frases em português também\n",
        "    por = por_vectorization(por)\n",
        "\n",
        "    # Retorna uma tupla com dois elementos:\n",
        "    # 1. Um dicionário contendo os inputs para o encoder e o decoder\n",
        "    #    - \"encoder_inputs\": sequências em inglês vetorizadas\n",
        "    #    - \"decoder_inputs\": sequências em português *até o penúltimo token*, usadas como entrada do decoder\n",
        "    # 2. O alvo (\"target\") para o treinamento: a mesma sequência em português, mas iniciando\n",
        "    # a partir do segundo token. Isso permite prever a próxima palavra a partir da anterior\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": por[:, :-1],\n",
        "        },\n",
        "        por[:, 1:],\n",
        "    )\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    # Separa os pares bilíngues em duas listas: textos em inglês e textos em português\n",
        "    eng_texts, por_texts = zip(*pairs)\n",
        "\n",
        "    # Converte as tuplas resultantes em listas (para compatibilidade com o TensorFlow)\n",
        "    eng_texts = list(eng_texts)\n",
        "    por_texts = list(por_texts)\n",
        "\n",
        "    # Cria um dataset do TensorFlow a partir dos pares de texto\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, por_texts))\n",
        "\n",
        "    # Agrupa os exemplos em lotes (batches) de tamanho `batch_size`\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Aplica a função `format_dataset` a cada lote do dataset\n",
        "    # Isso transforma texto em vetores e prepara os pares de entrada/saída para o modelo\n",
        "    dataset = dataset.map(format_dataset)\n",
        "\n",
        "    # Retorna o dataset com cache (para evitar recalcular), embaralhado e com prefetch (pré-carregamento)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "# Cria o dataset de treinamento a partir dos pares de treino\n",
        "train_ds = make_dataset(train_pairs)\n",
        "\n",
        "# Cria o dataset de validação a partir dos pares de validação\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "# Conferindo as sequencias: temos lotes de 64 pares e todas as sequências têm 20 passos de comprimento.\n",
        "for inputs, targets in train_ds.take(1):\n",
        "  print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "  print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "  print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMQ8dYzkn-p7"
      },
      "source": [
        "# **Contruindo o Modelo**\n",
        "\n",
        "Nosso modelo Transformer *sequence to sequence* é composto por um *Encoder* e um *Decoder* conectados em sequência. Para que o modelo reconheça a ordem das palavras, também utilizamos uma camada de *PositionalEmbedding* (Inserção de Posição).\n",
        "\n",
        "A sequência de origem será passada para o *Encoder*, que produzirá uma nova representação dela. Essa nova representação será então enviada ao *Decoder*, junto com a sequência de destino até o momento (palavras de destino de 0 até N). O *Decoder* terá como objetivo prever as próximas palavras na sequência de destino (N+1 e seguintes).\n",
        "\n",
        "Um detalhe fundamental que torna isso possível é a máscara causal (veja o método *get_causal_attention_mask()* no *Decoder*). O *Decoder* recebe toda a sequência de uma vez, e por isso precisamos garantir que ele utilize apenas informações dos tokens de destino de 0 até N ao prever o token N+1 (caso contrário, poderia usar informações do futuro, o que resultaria em um modelo que não pode ser usado durante a inferência)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XYMYg2jdn-p7"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        # Inicializa a camada base (Layer)\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Parâmetros importantes do encoder:\n",
        "        self.embed_dim = embed_dim   # Dimensão da embedding\n",
        "        self.dense_dim = dense_dim   # Dimensão da camada densa interna\n",
        "        self.num_heads = num_heads   # Número de heads na atenção multi-head\n",
        "\n",
        "        # Camada de atenção multi-head\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Rede feed-forward (projecção densa) com duas camadas\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Normalização das camadas (duas instâncias: uma antes e outra depois da rede densa)\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "        # Indica que esta camada suporta máscara (para lidar com sequências de diferentes comprimentos)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # Se houver máscara, converte-a para formato adequado\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        # Atenção multi-head: Q=V=K=inputs\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "\n",
        "        # Residual + LayerNorm 1\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "\n",
        "        # Passa pela rede densa\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "\n",
        "        # Residual + LayerNorm 2\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Método usado para serializar a configuração da camada\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Camada de embeddings dos tokens (vocabulário)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Camada de embeddings das posições (posições no tempo/sequência)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Guarda os parâmetros como atributos\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Pega o comprimento da sequência\n",
        "        length = ops.shape(inputs)[-1]\n",
        "\n",
        "        # Gera as posições (0 até length - 1)\n",
        "        positions = ops.arange(0, length, 1)\n",
        "\n",
        "        # Aplica a embedding dos tokens\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "\n",
        "        # Aplica a embedding das posições\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "\n",
        "        # Soma os dois embeddings (tokens + posições)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        # Define a máscara: ignora tokens com valor zero (padrão de preenchimento)\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Serializa a configuração da camada\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Parâmetros principais do decoder\n",
        "        self.embed_dim = embed_dim     # Dimensão da embedding\n",
        "        self.latent_dim = latent_dim # Dimensão latente da rede densa\n",
        "        self.num_heads = num_heads   # Número de heads na atenção multi-head\n",
        "\n",
        "        # Primeira atenção: autoatenção dentro do próprio decoder\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Segunda atenção: entre decoder e saída do encoder\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "\n",
        "        # Rede densa do decoder\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Três normalizações de camada para residual learning\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "\n",
        "        # Suporte à máscara (importante para inferência autoregressiva)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # Separa entrada do decoder e saída do encoder\n",
        "        inputs, encoder_outputs = inputs\n",
        "\n",
        "        # Gera a máscara causal (evita olhar para o futuro)\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        # Extrai máscaras de padding, se existirem\n",
        "        if mask is None:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = None, None\n",
        "        else:\n",
        "            inputs_padding_mask, encoder_outputs_padding_mask = mask\n",
        "\n",
        "        # Autoatenção: decoder consigo mesmo\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            query_mask=inputs_padding_mask,\n",
        "        )\n",
        "\n",
        "        # Residual + LayerNorm 1\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        # Atenção ao encoder (cross-attention)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            query_mask=inputs_padding_mask,\n",
        "            key_mask=encoder_outputs_padding_mask,\n",
        "        )\n",
        "\n",
        "        # Residual + LayerNorm 2\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        # Rede densa final\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "\n",
        "        # Residual + LayerNorm 3\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        # Cria a máscara causal para evitar leak de informações futuras\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "\n",
        "        # Cria matriz triangular inferior (cada posição só vê o passado)\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")  # [length, length]\n",
        "\n",
        "        # Expande a máscara para todos os elementos do batch\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        # Serializa a configuração da camada\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl_OZ8tAn-p7"
      },
      "source": [
        "# **Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SaNb3dAsn-p8"
      },
      "outputs": [],
      "source": [
        "# Define a dimensão dos embeddings (tamanho do vetor usado para representar palavras)\n",
        "embed_dim = 256\n",
        "\n",
        "# Dimensão latente usada nas camadas densas internas das camadas Transformer\n",
        "latent_dim = 2048\n",
        "\n",
        "# Número de heads na atenção multi-head - permite ao modelo aprender diferentes relações simultaneamente\n",
        "num_heads = 8\n",
        "\n",
        "# Cria a entrada para o encoder: sequência de tokens inteiros (palavras indexadas)\n",
        "encoder_inputs = keras.Input(\n",
        "    shape=(None,),  # Sequências de comprimento variável\n",
        "    dtype=\"int64\",   # Tokens são números inteiros (índices no vocabulário)\n",
        "    name=\"encoder_inputs\" # Nome da camada de entrada\n",
        ")\n",
        "\n",
        "# Aplica a embedding posicional às entradas do encoder:\n",
        "# Combina a embedding das palavras com a informação de posição\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "# Passa a entrada pelo encoder do Transformer:\n",
        "# Transforma a sequência fonte em uma representação contextualizada\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "\n",
        "# Define o modelo do encoder: mapeia as entradas para a saída do encoder\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "# Cria a entrada para o decoder: sequência de tokens (frase alvo até o momento)\n",
        "decoder_inputs = keras.Input(\n",
        "    shape=(None,),\n",
        "    dtype=\"int64\",\n",
        "    name=\"decoder_inputs\"\n",
        ")\n",
        "\n",
        "# Entrada adicional para o decoder: saída do encoder (representação da frase fonte)\n",
        "encoded_seq_inputs = keras.Input(\n",
        "    shape=(None, embed_dim),\n",
        "    name=\"decoder_state_inputs\"\n",
        ")\n",
        "\n",
        "## Aplica a embedding posicional à sequência de entrada do decoder\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "\n",
        "# Passa a entrada e o estado do encoder para o decoder do Transformer:\n",
        "# O decoder usa a saída do encoder para gerar a próxima palavra da sequência\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)([x, encoder_outputs])\n",
        "\n",
        "# Adiciona dropout para regularização (evitar overfitting)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Camada final: projeta os vetores do decoder para o tamanho do vocabulário,\n",
        "# produzindo probabilidades para cada palavra possível (usando softmax)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "# Define o modelo do decoder como um submodelo:\n",
        "# Recebe a entrada do decoder e o estado vindo do encoder, e gera a saída\n",
        "decoder = keras.Model(\n",
        "    [decoder_inputs, encoded_seq_inputs],\n",
        "    decoder_outputs\n",
        ")\n",
        "\n",
        "# Monta o modelo completo do Transformer:\n",
        "# Conecta as partes do encoder e do decoder\n",
        "transformer = keras.Model(\n",
        "    {\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b09ClvDfn-p8"
      },
      "source": [
        "# **Treinando o Modelo**\n",
        "\n",
        "Vamos usar a *acurácia* como métrica para monitorar o progresso do treinamento nos dados de validação.\n",
        "A tradução automática muitas vezes utiliza também a métrica BLEU (*Bilingual Evaluation Understudy*).\n",
        "\n",
        "No exemplo, vamos treinar por apenas 1 época, mas para que o modelo convergir, é necessário treiná-lo por pelo menos 30 épocas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1  # é necessário treiná-lo por pelo menos 30 épocas.\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\",\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(ignore_class=0),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "ZaLfntXkjTcb",
        "outputId": "74de472a-c4a0-4949-e455-391ffe0a108f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m15000\u001b[0m)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-3530671504.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m           )\n\u001b[1;32m    918\u001b[0m       )\n\u001b[0;32m--> 919\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    920\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAqCNvZCn-p8"
      },
      "source": [
        "## **Traduzindo as frase**\n",
        "\n",
        "Finalmente, vamos demonstrar como traduzir frases em inglês completamente novas, que não foram usadas no treinamento.\n",
        "\n",
        "Basta fornecer ao modelo a frase em inglês vetorizada e o token alvo \"[start]\", em seguida geramos repetidamente o próximo token, até que alcancemos o token \"[end]\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmIf50Fdn-p8"
      },
      "outputs": [],
      "source": [
        "# Obtém o vocabulário do vetorizador de português\n",
        "por_vocab = por_vectorization.get_vocabulary()\n",
        "\n",
        "# Cria um dicionário que mapeia índices para palavras no vocabulário\n",
        "# Isso permite converter índices previstos pelo modelo de volta para texto\n",
        "por_index_lookup = dict(zip(range(len(por_vocab)), por_vocab))\n",
        "\n",
        "# Define o comprimento máximo da frase traduzida gerada durante a inferência\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence]) # Vetoriza a frase de entrada (em inglês)\n",
        "    decoded_sentence = \"[start]\"  # Inicia a frase de saída com o token \"[start]\", indicando o início da tradução\n",
        "    # Loop para gerar a tradução palavra por palavra, até o limite definido\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        # Vetoriza a frase em português atual (até agora), excluindo o último token\n",
        "        tokenized_target_sentence = por_vectorization([decoded_sentence])[:, :-1]\n",
        "        # Passa as entradas pelo modelo:\n",
        "        # - tokenized_input_sentence: entrada do encoder (frase em inglês)\n",
        "        # - tokenized_target_sentence: entrada do decoder (até agora)\n",
        "        predictions = transformer(\n",
        "            {\n",
        "                \"encoder_inputs\": tokenized_input_sentence,\n",
        "                \"decoder_inputs\": tokenized_target_sentence,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Encontra o índice da palavra mais provável na posição atual\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "\n",
        "        # Converte o índice para a palavra real usando o dicionário de lookup\n",
        "        sampled_token = por_index_lookup[sampled_token_index]\n",
        "\n",
        "        # Adiciona a nova palavra à frase traduzida\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        # Se o token final \"[end]\" for alcançado, interrompe a geração\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    # Retorna a frase traduzida completa\n",
        "    return decoded_sentence\n",
        "\n",
        "# Extrai apenas as frases em inglês dos pares de teste\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "# Traduz e imprime 30 frases aleatórias do conjunto de teste\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts) # Escolhe uma frase aleatória do conjunto de teste\n",
        "    translated = decode_sequence(input_sentence)   # Gera a tradução usando o modelo treinado\n",
        "    print(f'{input_sentence} -> {translated}')     # Imprime a entrada e a tradução gerada"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}